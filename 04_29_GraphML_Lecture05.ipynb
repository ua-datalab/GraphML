{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXbfQhY5m8+0jdnibybvox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ua-datalab/GraphML/blob/main/04_29_GraphML_Lecture05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Graph ATtention networks (GATs)**"
      ],
      "metadata": {
        "id": "1zbObUbn9w3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Before we start, change the Runtime to T4**"
      ],
      "metadata": {
        "id": "ZGQSyizWDRtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Attention Networks (GATs), a key advancement from Graph Convolutional Networks (GCNs)(**from Tutorial 4**).\n",
        "\n",
        "### Unlike GCNs, which use static normalization coefficients, GATs employ dynamic weighting factors derived through a mechanism known as self-attention—a core feature in some of the most influential deep learning models, such as transformers, BERT, and GPT-3.\n",
        "\n",
        "### First introduced by [Veličković et al.](https://arxiv.org/abs/1710.10903) in 2017, GATs have gained popularity for their robust performance right out of the box."
      ],
      "metadata": {
        "id": "XhCKa3L5_3qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, we will explore the following topics:\n",
        "\n",
        "* Introduction to the graph attention layer\n",
        "* Implementing the graph attention layer using NumPy\n",
        "* Building a Graph Attention Network (GAT) with PyTorch Geometric\n",
        "\n"
      ],
      "metadata": {
        "id": "7vyZJ-emAicl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Graph Attention Networks (GATs)\n",
        "\n",
        "Graph Attention Networks (GATs) enhance the flexibility of graph neural networks by integrating node features into the weighting calculations, allowing for **dynamic attention scores** that surpass the **static weighting based solely on node degrees found in Graph Convolutional Networks** (GCNs).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mXm_XD_CDl7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kIrUlAaaHcw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Convolution vs. Graph Attention Layer\n",
        "\n",
        "### Limitations of Graph Convolutions (from Tutorial 4)\n",
        "\n",
        "### In traditional graph convolutional networks, the significance of nodes with fewer neighbors is amplified by the normalization coefficient. This coefficient is often calculated as:\n",
        "\n",
        "$$ \\frac{1}{\\sqrt{\\text{degree}(node_i) \\times \\text{degree}(node_j)}} $$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UXmEsSYnDmAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Attention layer"
      ],
      "metadata": {
        "id": "V7jRh-04P0XN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In contrast, the graph attention layer aims to produce weighting factors that incorporate both the structural context and the specific features of the nodes. These factors, referred to as \"attention scores,\" dynamically evaluate the importance of each neighboring node. For nodes $ i $ and any node $ j $ in the neighborhood $ N(i) $, the graph attention operation is defined as:\n",
        "\n",
        "$$ h_i = \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij} W x_j $$\n"
      ],
      "metadata": {
        "id": "NIQLdU3xDmDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Components of the Graph Attention Layer\n",
        "\n",
        "### Linear Transformation\n",
        "- **Purpose:** Each node feature undergoes a linear transformation, allowing for the integration of interactions between node pairs, which is critical for the layer's ability to focus on relevant information. This score takes into account the features from both nodes. In the graph attention layer, this relationship is captured by concatenating the hidden vectors of both nodes. The concatenated vector undergoes a linear transformation using a shared weight matrix $ W $, common for computing hidden vectors. This is further transformed by a dedicated, learnable weight matrix specifically designed to produce attention coefficients during the training process. This entire procedure is encapsulated by the following formula:\n",
        "\n",
        "$$ a_{ij} = W_a [Wx_i \\Vert Wx_j] $$\n",
        "\n",
        "### Activation Function\n",
        "- **Implementation:** Nonlinear functions such as Leaky ReLU are used to capture complex patterns that extend beyond simple linear combinations.\n",
        "- **Significance:** Nonlinearity is essential in neural networks to approximate nonlinear target functions effectively.\n",
        "\n",
        "The output from the previous step is then processed through a Leaky ReLU function. The **Leaky ReLU** introduces a small slope for negative values, allowing for a small, non-zero gradient when the unit is not active. This is represented by the equation:\n",
        "$$ y = \\max(0.01x, x) $$\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize:fit:720/format:webp/0*6DZve_x3t08PcwYm.JPG)\n",
        "\n",
        "### Softmax Normalization\n",
        "- **Function:** Normalizes attention scores across all nodes to ensure they are comparable, which is crucial for the model's training stability.\n",
        "- **Method:** Typically, the softmax function is employed for this purpose, scaling the attention scores in a way that they sum to one across the nodes' neighborhood.\n",
        "\n",
        "To effectively compare attention scores across different nodes, we must normalize these values to ensure they are on the same scale. This normalization commonly uses the softmax function in machine learning. For node $ i $ and its neighboring nodes, including itself, the softmax function is applied to calculate the normalized attention scores. The softmax calculation for\n",
        "$ \\alpha_{ij} $ is given by:\n",
        "\n",
        "$$ \\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{e^{e_{ij}}}{\\sum_{k \\in \\mathcal{N}(i)} e^{e_{ik}}} $$\n",
        "\n",
        "\n",
        "### Multi-head Attention\n",
        "- **Inspiration:** Borrowed from transformer architectures, this technique uses multiple sets of attention mechanisms simultaneously to diversify the learning and enhance model stability.\n",
        "- **Benefits:** Multi-head attention allows the model to capture various aspects of the data in parallel, improving performance and robustness.\n",
        "\n",
        "Multi-head attention addresses the drawbacks of self-attention by diversifying the attention mechanism:\n",
        "\n",
        "Multiple Embeddings: By calculating multiple sets of attention scores and corresponding embeddings, multi-head attention allows the model to explore different aspects of the data in parallel. Each \"head\" of attention can focus on different relationships in the data, capturing a broader range of features than a single set of attention scores could.\n",
        "\n",
        "Combining Results:\n",
        "Averaging: The outputs from multiple heads are averaged. This method reduces variance in the attention outputs, as it smooths out the extreme values that might be produced by any single attention head.\n",
        "\n",
        "$$ h_i = \\frac{1}{n} \\sum_{k=1}^{n} h_i^k = \\frac{1}{n} \\sum_{k=1}^{n} \\sum_{j \\in N_i} \\alpha_{ij}^k W^k x_j $$\n",
        "\n",
        "Concatenation: Alternatively, the outputs from all heads are concatenated to form a larger feature space. This method preserves the distinct perspectives from each head, enhancing the model’s capacity to represent complex data relationships.\n",
        "\n",
        "$$ h_i = \\|_{k=1}^{n} h_i^k = \\|_{k=1}^{n} \\sum_{j \\in N_i} \\alpha_{ij}^k W^k x_j $$\n"
      ],
      "metadata": {
        "id": "MBKrURA2DmGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v4kKaYaTm1oA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In matrix form:\n",
        "\n",
        "$$ h_i = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} W x_j $$\n",
        "\n",
        "\n",
        "## and the  graph attention layer can be written as\n",
        "$$\n",
        "H = \\tilde{A}^TW_{\\alpha} X W^T\n",
        "$$"
      ],
      "metadata": {
        "id": "LqcJ0M0Um1tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementing Graph Attention in Numpy**"
      ],
      "metadata": {
        "id": "10Dw_LKODmI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CYVy0BmSnpTk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "\n",
        "### Considering the following adjacency matrix $ A $;  with self loops version"
      ],
      "metadata": {
        "id": "veMOJ2eUn7ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "    [1, 1, 1, 1],\n",
        "    [1, 1, 0, 0],\n",
        "    [1, 0, 1, 1],\n",
        "    [1, 0, 1, 1]\n",
        "])\n"
      ],
      "metadata": {
        "id": "9gchkqdznqDk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a graph from the adjacency matrix\n",
        "G = nx.from_numpy_array(A)\n",
        "mapping = {i: i  for i in range(len(G.nodes))}\n",
        "G = nx.relabel_nodes(G, mapping)\n",
        "\n",
        "# Draw the graph with labels starting from 1\n",
        "plt.figure(figsize=(4, 4))\n",
        "nx.draw(G, with_labels=True, font_color='#ffffff', node_size=1000, node_color=\"#00b4d9\", font_size=15, font_weight='bold', edge_color='gray')\n",
        "plt.title(\"Graph Representation of the Adjacency Matrix A\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "--6ZRl8OnqJk",
        "outputId": "51398b39-bd8a-4afc-f817-dea57405137f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For feature vector: we generate from a normal distribution using numpy"
      ],
      "metadata": {
        "id": "d-Do_VjNov3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.uniform(-1, 1, (4, 4))"
      ],
      "metadata": {
        "id": "uyU4QDRanqMc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQDB8REwnqPU",
        "outputId": "b39594c8-0b72-44cc-f314-588d15dde1b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.83138904,  0.14795564, -0.58015326,  0.60504443],\n",
              "       [-0.34975839, -0.43945714, -0.16305606, -0.87422746],\n",
              "       [-0.30119075, -0.56359775,  0.68631308,  0.750651  ],\n",
              "       [ 0.33475158, -0.977144  ,  0.0493458 ,  0.03906593]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving forward, we need to establish the weight matrices that are pivotal in graph attention layers. Specifically, there are two distinct matrices: the standard weight matrix, often denoted as\n",
        "$ W $, and the weight matrix dedicated to attention, denoted as\n",
        "${W}_{att}$ . While various initialization techniques exist, such as Xavier or He initialization, to tailor the matrices to optimize learning, in this instance, we can simply apply a uniform random initialization function for illustrative purposes."
      ],
      "metadata": {
        "id": "4FPudzQGrdBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = np.random.uniform(-1, 1, (2, 4))\n",
        "W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXTiDG_TnqR1",
        "outputId": "4b791818-2724-4c5a-9630-c7567048b37b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.69147076, -0.89047094, -0.53993022,  0.81700251],\n",
              "       [ 0.01727098,  0.74841087,  0.49252491,  0.26758988]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_att = np.random.uniform(-1, 1, (1, 4))\n",
        "W_att"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffb_Aq8InqXU",
        "outputId": "4f741451-74df-4833-893b-9667d669a127"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.88761142, -0.20199502,  0.81996747,  0.62586948]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting source and destination nodes"
      ],
      "metadata": {
        "id": "xohVqt50r__V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connections = np.where(A > 0)\n",
        "connections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMjCOrmtnqZ0",
        "outputId": "b4dfa16d-4911-460c-a79a-a588f9988b8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3]),\n",
              " array([0, 1, 2, 3, 0, 1, 0, 2, 3, 0, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, We can concatenate hidden vectors of source and destination nodes"
      ],
      "metadata": {
        "id": "6UTePvLMsYqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate([(X @ W.T)[connections[0]], (X @ W.T)[connections[1]]], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-7fzjijnqck",
        "outputId": "448f26b1-ae55-490c-ae06-bf6901b90f0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.10093369, -0.02746346,  0.10093369, -0.02746346],\n",
              "       [ 0.10093369, -0.02746346, -0.47673102, -0.64917876],\n",
              "       [ 0.10093369, -0.02746346,  0.5363254 ,  0.11188835],\n",
              "       [ 0.10093369, -0.02746346,  1.10686294, -0.69076603],\n",
              "       [-0.47673102, -0.64917876,  0.10093369, -0.02746346],\n",
              "       [-0.47673102, -0.64917876, -0.47673102, -0.64917876],\n",
              "       [ 0.5363254 ,  0.11188835,  0.10093369, -0.02746346],\n",
              "       [ 0.5363254 ,  0.11188835,  0.5363254 ,  0.11188835],\n",
              "       [ 0.5363254 ,  0.11188835,  1.10686294, -0.69076603],\n",
              "       [ 1.10686294, -0.69076603,  0.10093369, -0.02746346],\n",
              "       [ 1.10686294, -0.69076603,  0.5363254 ,  0.11188835],\n",
              "       [ 1.10686294, -0.69076603,  1.10686294, -0.69076603]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying a linear transformation to this result with the attention matrix"
      ],
      "metadata": {
        "id": "mNO70m5l2wjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = W_att @ np.concatenate([(X @ W.T)[connections[0]], (X @ W.T)[connections[1]]], axis=1).T"
      ],
      "metadata": {
        "id": "ULLZWd5U2wqV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying a Leaky ReLU function"
      ],
      "metadata": {
        "id": "bKhymFKn2wxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu(x, alpha=0.2):\n",
        "    return np.maximum(alpha*x, x)\n",
        "\n",
        "e = leaky_relu(a)\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jJufX5p2w39",
        "outputId": "dd76b001-1a27-43b5-b36d-b54c7201cf0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16071118, -0.14041354,  0.60493426,  0.57039961, -0.04528944,\n",
              "        -0.21784523,  0.51902146,  0.96324454,  0.92870988,  1.18756929,\n",
              "         1.63179237,  1.59725771]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqS8wLV83MHA",
        "outputId": "e36cc868-999a-41b3-c68c-27a22249a90e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This matrix should resemble $ \\tilde{A} $   since unnormalized attention scores are redundant for node pairs that do not share a connection. We can construct this matrix accurately because the existing connections provide us with the necessary information about the source and destination nodes."
      ],
      "metadata": {
        "id": "teBM4nev2w-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "E = np.zeros(A.shape)\n",
        "E[connections[0], connections[1]] = e[0]\n",
        "E"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxm16dLy2xEF",
        "outputId": "961541aa-aa5b-40a0-837a-30c5e1b70078"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16071118, -0.14041354,  0.60493426,  0.57039961],\n",
              "       [-0.04528944, -0.21784523,  0.        ,  0.        ],\n",
              "       [ 0.51902146,  0.        ,  0.96324454,  0.92870988],\n",
              "       [ 1.18756929,  0.        ,  1.63179237,  1.59725771]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Adjust each row of attention scores to a standard scale by applying a tailored softmax function, which will yield our ultimate attention coefficients."
      ],
      "metadata": {
        "id": "cV1Y8T3i2xJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax2D(x, axis):\n",
        "    e = np.exp(x - np.expand_dims(np.max(x, axis=axis), axis))\n",
        "    sum = np.expand_dims(np.sum(e, axis=axis), axis)\n",
        "    return e / sum\n",
        "\n",
        "W_alpha = softmax2D(E, 1)\n",
        "W_alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_G4OHet2xP9",
        "outputId": "cf2d3d62-8b56-4522-dbc9-bca9cb0bb2ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20809004, 0.1539836 , 0.32447027, 0.31345609],\n",
              "       [0.25418305, 0.21389792, 0.26595952, 0.26595952],\n",
              "       [0.2145587 , 0.12768444, 0.33455672, 0.32320015],\n",
              "       [0.22880215, 0.06977588, 0.35676623, 0.34465575]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The attention matrix\n",
        "$ α  $ assigns weights to every potential link within the network. Utilizing this matrix, we can compute our embedding matrix\n",
        "$ H $, resulting in two-dimensional vector representations for each node."
      ],
      "metadata": {
        "id": "sjETmv_12xV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = A.T @ W_alpha @ X @ W.T"
      ],
      "metadata": {
        "id": "V7YGsCw62xb1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1MvTZx167Yv",
        "outputId": "2c31c55a-b347-402a-ac78-6fdb76e4a2b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.88988813, -1.11003933],\n",
              "       [ 0.82927455, -0.58569489],\n",
              "       [ 1.52918269, -0.81024257],\n",
              "       [ 1.52918269, -0.81024257]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our graph attention layer is fully assembled! To incorporate multi-head attention, we replicate the process using varied instances of weight matrices and attention mechanisms, followed by a combination of their outputs."
      ],
      "metadata": {
        "id": "9fDHIpJQ2xhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gn0eO84g6-a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GAT in PyTorch Geometric** - Working out examples from previous Tutorials"
      ],
      "metadata": {
        "id": "wrE3bb806_s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icbRVKOl-Vic",
        "outputId": "e7fe44c1-dc8b-4b98-94b1-b82edd49b00f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m977.0 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m0.9/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid,FacebookPagePage\n",
        "from torch_geometric.utils import degree\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OWk5Kq7a-Vk7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Cora Dataset**"
      ],
      "metadata": {
        "id": "GdCx2Ctv_QXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset from PyTorch Geometric\n",
        "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
        "data = dataset[0]\n",
        "degrees = degree(data.edge_index[0]).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQGys7i--Vnr",
        "outputId": "0e627643-d4ad-4bd9-f265-088fbfa440ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(1)\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch.nn import Linear, Dropout"
      ],
      "metadata": {
        "id": "oS3L0PIA-Vqb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return torch.sum(y_pred == y_true) / len(y_true)"
      ],
      "metadata": {
        "id": "-GUc9l4e-Vsz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
        "        super().__init__()\n",
        "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
        "        self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = F.dropout(x, p=0.6, training=self.training)\n",
        "        h = self.gat1(h, edge_index)\n",
        "        h = F.elu(h)\n",
        "        h = F.dropout(h, p=0.6, training=self.training)\n",
        "        h = self.gat2(h, edge_index)\n",
        "        return F.log_softmax(h, dim=1)\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=0.01)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x, data.edge_index)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if(epoch % 20 == 0):\n",
        "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x, data.edge_index)\n",
        "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
        "        return acc"
      ],
      "metadata": {
        "id": "D0g9eF2d-VyT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the GAT model\n",
        "gat = GAT(dataset.num_features, 16, dataset.num_classes)\n",
        "print(gat)\n",
        "\n",
        "# Train\n",
        "gat.fit(data, epochs=100)\n",
        "\n",
        "# Test\n",
        "acc = gat.test(data)\n",
        "print(f'GAT test accuracy: {acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtnuYIel-V1D",
        "outputId": "2578cfef-6b11-4cb9-ec3c-10fb9860d895"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (gat1): GATv2Conv(1433, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 7, heads=1)\n",
            ")\n",
            "Epoch   0 | Train Loss: 1.983 | Train Acc: 12.14% | Val Loss: 1.98 | Val Acc: 10.60%\n",
            "Epoch  20 | Train Loss: 0.186 | Train Acc: 99.29% | Val Loss: 0.87 | Val Acc: 74.20%\n",
            "Epoch  40 | Train Loss: 0.152 | Train Acc: 97.86% | Val Loss: 0.86 | Val Acc: 72.40%\n",
            "Epoch  60 | Train Loss: 0.167 | Train Acc: 97.14% | Val Loss: 0.84 | Val Acc: 76.40%\n",
            "Epoch  80 | Train Loss: 0.144 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 74.40%\n",
            "Epoch 100 | Train Loss: 0.143 | Train Acc: 98.57% | Val Loss: 0.77 | Val Acc: 75.20%\n",
            "GAT test accuracy: 83.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The FB Page-Page dataset**"
      ],
      "metadata": {
        "id": "wR_gTV5j_tNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset from PyTorch Geometric\n",
        "dataset = FacebookPagePage(root=\".\")\n",
        "data = dataset[0]\n",
        "\n",
        "# Create masks\n",
        "data.train_mask = range(18000)\n",
        "data.val_mask = range(18001, 20000)\n",
        "data.test_mask = range(20001, 22470)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-5OYsiO-V4D",
        "outputId": "c70dd238-b08a-4490-bf90-e3a2ba6b2727"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://graphmining.ai/datasets/ptg/facebook.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gat = GAT(dataset.num_features, 32, dataset.num_classes)\n",
        "print(gat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5AbJqoV-V6z",
        "outputId": "35fd2e68-10eb-4d27-9ecd-3ee3c07ab061"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (gat1): GATv2Conv(128, 32, heads=8)\n",
            "  (gat2): GATv2Conv(256, 4, heads=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "gat.fit(data, epochs=100)\n",
        "\n",
        "# Test\n",
        "acc = gat.test(data)\n",
        "print(f'GAT test accuracy: {acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J01k9S71-V9j",
        "outputId": "e98e3434-abfc-4b41-e71f-daf6cd97e94a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Train Loss: 1.798 | Train Acc: 27.40% | Val Loss: 1.82 | Val Acc: 26.86%\n",
            "Epoch  20 | Train Loss: 0.364 | Train Acc: 87.23% | Val Loss: 0.36 | Val Acc: 87.29%\n",
            "Epoch  40 | Train Loss: 0.350 | Train Acc: 88.49% | Val Loss: 0.34 | Val Acc: 89.04%\n",
            "Epoch  60 | Train Loss: 0.341 | Train Acc: 88.21% | Val Loss: 0.34 | Val Acc: 88.44%\n",
            "Epoch  80 | Train Loss: 0.331 | Train Acc: 88.91% | Val Loss: 0.33 | Val Acc: 89.39%\n",
            "Epoch 100 | Train Loss: 0.340 | Train Acc: 88.40% | Val Loss: 0.34 | Val Acc: 88.69%\n",
            "GAT test accuracy: 91.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAT on the CiteSeer and Pubmed dataset from Tutorial 3"
      ],
      "metadata": {
        "id": "GhzNY7F2CUZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_CSeer = Planetoid(root=\".\", name=\"CiteSeer\")\n",
        "data_graph_CSeer = dataset_CSeer[0] # get the citeseer graph\n",
        "\n",
        "dataset_PM = Planetoid(root=\".\", name=\"PubMed\")\n",
        "data_graph_PM = dataset_PM[0] # the Pubmed graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4w9jFco-WAT",
        "outputId": "33e92d9c-6c5b-41f8-afbe-2458acd586ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAT on Citeseer**"
      ],
      "metadata": {
        "id": "lI4GegRRCe6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat = GAT(dataset_CSeer.num_features, 32, dataset_CSeer.num_classes)\n",
        "print(gat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFvOubN-CfBb",
        "outputId": "727ee985-b20b-4d0a-ba91-da943ed757c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (gat1): GATv2Conv(3703, 32, heads=8)\n",
            "  (gat2): GATv2Conv(256, 6, heads=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "gat.fit(data_graph_CSeer, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1SN5L0dCfMj",
        "outputId": "6bc8357b-385a-4d43-aea9-8f9128d79092"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Train Loss: 1.795 | Train Acc: 20.00% | Val Loss: 1.80 | Val Acc: 18.20%\n",
            "Epoch  20 | Train Loss: 0.178 | Train Acc: 96.67% | Val Loss: 1.21 | Val Acc: 60.80%\n",
            "Epoch  40 | Train Loss: 0.159 | Train Acc: 96.67% | Val Loss: 1.22 | Val Acc: 56.60%\n",
            "Epoch  60 | Train Loss: 0.114 | Train Acc: 100.00% | Val Loss: 1.21 | Val Acc: 60.60%\n",
            "Epoch  80 | Train Loss: 0.109 | Train Acc: 100.00% | Val Loss: 1.25 | Val Acc: 59.80%\n",
            "Epoch 100 | Train Loss: 0.083 | Train Acc: 99.17% | Val Loss: 1.17 | Val Acc: 62.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "acc = gat.test(data_graph_CSeer)\n",
        "print(f'\\nGAT test accuracy on CiteSeer Dataset: {acc*100:.2f}%\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18lfQmmzCfYj",
        "outputId": "0374158b-909f-46e7-bb86-d8c248e70bd1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GAT test accuracy on CiteSeer Dataset: 68.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Comparison\n",
        "%%html\n",
        "<table style=\"width:70%; margin-left:auto; margin-right:auto;\" border=\"1\">\n",
        "  <tr style=\"background-color: #f2f2f2;\">\n",
        "    <th style=\"padding: 10px; text-align:center;\">Dataset</th>\n",
        "    <th style=\"padding: 10px; text-align:center;\">MLP (Tutorial 3)</th>\n",
        "    <th style=\"padding: 10px; text-align:center;\">Vanilla GNN (Tutorial 3)</th>\n",
        "    <th style=\"padding: 10px; text-align:center;\">GCN (Tutorial 4)</th>\n",
        "    <th style=\"padding: 10px; text-align:center;\">GAT </th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 10px; text-align:center;\">Cora</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">53.40%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">75.00%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">80.60%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">83.30%</td>\n",
        "  </tr>\n",
        "  <tr style=\"background-color: #f9f9f9;\">\n",
        "    <td style=\"padding: 10px; text-align:center;\">Facebook Page-Page</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">75.13%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">82.67%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">91.21%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">91.45%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 10px; text-align:center;\">CiteSeer</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">52.70%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">65.50%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">68.10%</td>\n",
        "    <td style=\"padding: 10px; text-align:center;\">68.90%</td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "4kLa23BXEXB3",
        "outputId": "2f622afe-4983-4816-d07c-cf12a39bc166"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"width:70%; margin-left:auto; margin-right:auto;\" border=\"1\">\n",
              "  <tr style=\"background-color: #f2f2f2;\">\n",
              "    <th style=\"padding: 10px; text-align:center;\">Dataset</th>\n",
              "    <th style=\"padding: 10px; text-align:center;\">MLP (Tutorial 3)</th>\n",
              "    <th style=\"padding: 10px; text-align:center;\">Vanilla GNN (Tutorial 3)</th>\n",
              "    <th style=\"padding: 10px; text-align:center;\">GCN (Tutorial 4)</th>\n",
              "    <th style=\"padding: 10px; text-align:center;\">GAT </th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"padding: 10px; text-align:center;\">Cora</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">53.40%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">75.00%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">80.60%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">83.30%</td>\n",
              "  </tr>\n",
              "  <tr style=\"background-color: #f9f9f9;\">\n",
              "    <td style=\"padding: 10px; text-align:center;\">Facebook Page-Page</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">75.13%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">82.67%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">91.21%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">91.45%</td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"padding: 10px; text-align:center;\">CiteSeer</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">52.70%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">65.50%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">68.10%</td>\n",
              "    <td style=\"padding: 10px; text-align:center;\">68.90%</td>\n",
              "  </tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Node Regression**"
      ],
      "metadata": {
        "id": "PlFIDPKpH6e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Refer to Tutorial 4 for details of the Wikipedia Dataset**"
      ],
      "metadata": {
        "id": "8Hf8yngYPC2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "3aS9ApwmIAJU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WikipediaNetwork(root=\".\", name=\"chameleon\", transform = T.RandomNodeSplit(num_val=200, num_test=500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFbEM4VrICTS",
        "outputId": "d739d0b4-942a-468c-ab5b-20f655596707"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_9.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "UC9pUtABIEOr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOJyQrMYNNrB",
        "outputId": "028e8832-fdc2-4c32-cc25-3938e41679ad"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpG8d8DnNLtB",
        "outputId": "a87e6f4b-c27d-4e30-de1d-17a573477ecf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277], val_mask=[2277], test_mask=[2277])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('-------------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {data.x.shape[0]}')\n",
        "print(f'Number of unique features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has loops: {data.has_self_loops()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTUKG5JKIERD",
        "outputId": "41df0d9f-53df-4934-f864-357e031732f1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: WikipediaNetwork()\n",
            "-------------------\n",
            "Number of graphs: 1\n",
            "Number of nodes: 2277\n",
            "Number of unique features: 2325\n",
            "Number of classes: 5\n",
            "\n",
            "Graph:\n",
            "------\n",
            "Edges are directed: True\n",
            "Graph has isolated nodes: False\n",
            "Graph has loops: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "url = 'https://snap.stanford.edu/data/wikipedia.zip'\n",
        "with urlopen(url) as zurl:\n",
        "    with ZipFile(BytesIO(zurl.read())) as zfile:\n",
        "        zfile.extractall('.')"
      ],
      "metadata": {
        "id": "kAD3TuX4IETi"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "df = pd.read_csv('/content/wikipedia/chameleon/musae_chameleon_target.csv')\n",
        "values = np.log10(df['target'])\n",
        "data.y = torch.tensor(values)\n",
        "data.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQbqAvzaIEYs",
        "outputId": "3dd0fa8e-8f0c-449e-85db-ffa423246313"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.2330, 3.9079, 3.9329,  ..., 1.9956, 4.3598, 2.4409],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8o6dc9RNV2f",
        "outputId": "1eaea6eb-d455-46e0-e51c-f7aeacc45361"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is an object or dictionary containing 'x', 'y', and masks\n",
        "# data.x = data.x.to(device)\n",
        "data.y = data.y.to(device)\n",
        "# data.train_mask = data.train_mask.to(device)\n",
        "# data.val_mask = data.val_mask.to(device)"
      ],
      "metadata": {
        "id": "S7hr_1JLIEbT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.y = data.y.to(torch.float32).flatten().unsqueeze(1)"
      ],
      "metadata": {
        "id": "oDNR-5csIEdr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmW9_v7pIEiz",
        "outputId": "f34d7ec7-ce8a-4cfc-d314-86e0165e0b82"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2277, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "Z0X8O68dIElb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GAT on Wikipedia Chamelon Dataset**"
      ],
      "metadata": {
        "id": "ub9XEvLCIh3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATreg(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "        self.gat1 = GATv2Conv(dim_in, dim_h*4)\n",
        "        self.gat2 = GATv2Conv(dim_h*4, dim_h*2)\n",
        "        self.gat3 = GATv2Conv(dim_h*2, dim_h)\n",
        "        self.linear = torch.nn.Linear(dim_h, dim_out)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = self.gat1(x, edge_index)\n",
        "        h = torch.relu(h)\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.gat2(h, edge_index)\n",
        "        h = torch.relu(h)\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.gat3(h, edge_index)\n",
        "        h = torch.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        optimizer = torch.optim.Adam(self.parameters(),lr=0.02,weight_decay=5e-4)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x, data.edge_index)\n",
        "            loss = F.mse_loss(out.squeeze()[data.train_mask], data.y[data.train_mask].float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if epoch % 20 == 0:\n",
        "                val_loss = F.mse_loss(out.squeeze()[data.val_mask], data.y[data.val_mask])\n",
        "                print(f\"Epoch {epoch:>3} | Train Loss: {loss:.5f} | Val Loss: {val_loss:.5f}\")\n",
        "\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x, data.edge_index)\n",
        "        return F.mse_loss(out.squeeze()[data.test_mask], data.y[data.test_mask].float())"
      ],
      "metadata": {
        "id": "RsPsIG3oIgB3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfEaRlOmIgEe",
        "outputId": "4d9802da-276f-4a04-8600-05b1ac487130"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2277, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.y = data.y.to(torch.float32).flatten()"
      ],
      "metadata": {
        "id": "K_Tv-0r8IgHG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Vanilla GNN model\n",
        "gat = GATreg(dataset.num_features, 256, 1).to(device)\n",
        "print(gat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDoB1ZdLIgJt",
        "outputId": "8691381e-3f54-4615-f400-73c51b768a2c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GATreg(\n",
            "  (gat1): GATv2Conv(2325, 1024, heads=1)\n",
            "  (gat2): GATv2Conv(1024, 512, heads=1)\n",
            "  (gat3): GATv2Conv(512, 256, heads=1)\n",
            "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gat.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btWlFEPzMzyW",
        "outputId": "e52a2673-9290-47d9-c2f0-ad7313e2e5d3"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GATreg(\n",
              "  (gat1): GATv2Conv(2325, 1024, heads=1)\n",
              "  (gat2): GATv2Conv(1024, 512, heads=1)\n",
              "  (gat3): GATv2Conv(512, 256, heads=1)\n",
              "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x = data.x.to(device)\n",
        "data.y = data.y.to(device)\n",
        "data.train_mask = data.train_mask.to(device)\n",
        "data.val_mask = data.val_mask.to(device)"
      ],
      "metadata": {
        "id": "WEC2bqclM_m4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "gat.fit(data, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUUEj89IgOW",
        "outputId": "94c35b59-da40-4c21-f1ea-b95bdbf09cec"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Train Loss: 11.74721 | Val Loss: 11.38480\n",
            "Epoch  20 | Train Loss: 4.39063 | Val Loss: 3.70110\n",
            "Epoch  40 | Train Loss: 1.01277 | Val Loss: 1.66626\n",
            "Epoch  60 | Train Loss: 2.81941 | Val Loss: 1.10955\n",
            "Epoch  80 | Train Loss: 0.47918 | Val Loss: 0.66514\n",
            "Epoch 100 | Train Loss: 0.36154 | Val Loss: 0.68024\n",
            "Epoch 120 | Train Loss: 0.40567 | Val Loss: 0.74111\n",
            "Epoch 140 | Train Loss: 0.34980 | Val Loss: 0.76104\n",
            "Epoch 160 | Train Loss: 0.43728 | Val Loss: 0.76894\n",
            "Epoch 180 | Train Loss: 0.31224 | Val Loss: 0.64963\n",
            "Epoch 200 | Train Loss: 0.30172 | Val Loss: 0.68591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "loss = gat.test(data)\n",
        "print(f'\\nGAT test loss: {loss:.5f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9-4owF-NjRr",
        "outputId": "35b8dcb3-9504-4367-ed5c-ef787d8b860b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GAT test loss: 0.50959\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = gat(data.x, data.edge_index)"
      ],
      "metadata": {
        "id": "wDBaRykBIgTm"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.cpu()"
      ],
      "metadata": {
        "id": "qR08P0rVJJ7P"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = out.squeeze()[data.test_mask.cpu()].detach().numpy()"
      ],
      "metadata": {
        "id": "WWOExY85JJ91"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(data.y[data.test_mask].squeeze().cpu(), y_pred)\n",
        "mae = mean_absolute_error(data.y[data.test_mask].squeeze().cpu(), y_pred)"
      ],
      "metadata": {
        "id": "OgcWD_-HJKAN"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('=' * 13 + '  GAT Wikipedia Chameleon Dataset  ' + '=' * 13)\n",
        "print(f'MSE = {mse:.4f} | RMSE = {np.sqrt(mse):.4f} | MAE = {mae:.4f}')\n",
        "print('=' * 57)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e32uT4_JKCh",
        "outputId": "d94b8e2a-a32a-4473-bed9-396976a12f87"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============  GAT Wikipedia Chameleon Dataset  =============\n",
            "MSE = 0.5096 | RMSE = 0.7139 | MAE = 0.5634\n",
            "=========================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model & Dataset                          | MSE  ⬇  | RMSE  ⬇ | MAE  ⬇  |\n",
        "|------------------------------------------|--------|--------|--------|\n",
        "| **MLP** on Wikipedia Chameleon Dataset       | 1.0280 | 1.0139 | 0.7373 |\n",
        "| **GCN** on Wikipedia Chameleon Dataset        | 0.5947 | 0.7711 | 0.6059 |\n",
        "| **GAT** on Wikipedia Chameleon Dataset        | 0.5096 | 0.7139 | 0.5634 |"
      ],
      "metadata": {
        "id": "onmMNQtzJXXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank you!**"
      ],
      "metadata": {
        "id": "JrXs3-LROyaJ"
      }
    }
  ]
}